import os
import base64
import subprocess
import sys
import importlib
import platform
import glob
import random
import psutil
import socket
import time
import torch
import numpy as np
import cv2
import tensorflow as tf
from colorama import init, Fore
from tensorflow.keras import layers, Model, Input, models, regularizers
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from typing import Dict, Optional, Tuple, List, Union
import logging
from dataclasses import dataclass, field
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('utn.log')
    ]
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Ç—Ä–µ–±—É–µ–º—ã—Ö –º–æ–¥—É–ª–µ–π
@dataclass
class Config:
    # –†–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π –∫–∞—á–µ—Å—Ç–≤–∞
    IMAGE_SIZES: Dict[int, int] = field(default_factory=lambda: {
        1: 32,  # –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
        2: 64,  # –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
        3: 128  # –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
    })
    # –°–ø–∏—Å–æ–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–æ–¥—É–ª–µ–π —Å –∏—Ö –≤–µ—Ä—Å–∏—è–º–∏
    REQUIRED_MODULES: Dict[str, Optional[str]] = field(default_factory=lambda: {
        "colorama": None,
        "tensorflow": "2.10",
        "numpy": "1.26.4",
        "opencv-python": None,
        "psutil": None,
        "scikit-learn": None
    })

config = Config()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã
error = False
IS_LINUX = platform.system() == "Linux"
IS_WINDOWS = platform.system() == "Windows"

def install_module(module: str, version: Optional[str] = None) -> None:
    """
    –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç Python –º–æ–¥—É–ª—å —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π.
    
    Args:
        module: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏
        version: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –º–æ–¥—É–ª—è
    """
    package = f"{module}=={version}" if version else module
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —á–µ—Ä–µ–∑ pip
        pip_args = [
            sys.executable, "-m", "pip", "install", package,
            "--disable-pip-version-check", "--no-warn-script-location"
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–ª–∞–≥ –¥–ª—è Linux —Å–∏—Å—Ç–µ–º
        if IS_LINUX:
            pip_args.append("--break-system-packages")
            
        # –í—ã–ø–æ–ª–Ω—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É –º–æ–¥—É–ª—è
        subprocess.run(
            pip_args,
            check=True,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
        logger.info(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {package}")
    except subprocess.CalledProcessError as e:
        global error
        error = True
        logger.error(f"–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ {package}: {str(e)}")

def check_internet() -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ –ø–æ–ø—ã—Ç–∫—É –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ DNS —Å–µ—Ä–≤–µ—Ä—É Google.
    
    Returns:
        bool: True –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    try:
        socket.create_connection(("8.8.8.8", 53), timeout=3)
        return True
    except OSError:
        return False

def get_available_memory() -> Tuple[float, float, str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏ GPU –∏ CPU.
    
    Returns:
        Tuple[float, float, str]: (VRAM –≤ –ì–ë, DRAM –≤ –ì–ë, –Ω–∞–∑–≤–∞–Ω–∏–µ GPU)
    """
    vram = 0.0
    gpu_name = "CPU"
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ CUDA GPU
        if torch.cuda.is_available():
            vram = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            gpu_name = torch.cuda.get_device_name(0)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ ROCm (AMD GPU)
        elif hasattr(torch.version, 'hip') and torch.version.hip is not None:
            gpu_name = "AMD ROCm"
            try:
                import torch_hip
                vram = torch_hip.get_device_properties(0).total_memory / (1024**3)
            except:
                vram = 1.0  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è AMD GPU
        elif tf.config.list_physical_devices('GPU'):
            gpu_name = "NVIDIA CUDA"
            vram = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ GPU: {str(e)}")
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω–æ–π –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏
    dram = psutil.virtual_memory().available / (1024 ** 3)
    return vram, dram, gpu_name

def load_utkface_data(path: str, img_size: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ UTKFace.
    
    Args:
        path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        img_size: –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ä–µ—Å–∞–π–∑–∞
    
    Returns:
        Tuple[np.ndarray, np.ndarray, np.ndarray]: (X, y_age, y_gender)
    """
    X, y_age, y_gender = [], [], []
    processed_count = 0
    error_count = 0
    
    try:
        # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è OpenCV –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã –≤—ã–≤–æ–¥–∞
        cv2.setLogLevel(0)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for filename in glob.glob(os.path.join(path, "*.jpg")):
            try:
                basename = os.path.basename(filename)
                parts = basename.split('_')
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                if len(parts) < 3:
                    logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª {basename}: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–º–µ–Ω–∏")
                    error_count += 1
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–æ–∑—Ä–∞—Å—Ç –∏ –ø–æ–ª –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                try:
                    age = int(parts[0])
                    gender = int(parts[1])
                except ValueError:
                    logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª {basename}: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞ –∏–ª–∏ –ø–æ–ª–∞")
                    error_count += 1
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª–∞
                if gender not in [0, 1]:
                    logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª {basename}: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª–∞")
                    error_count += 1
                    continue
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                img = cv2.imread(filename)
                if img is None:
                    logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª {basename}: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                    error_count += 1
                    continue
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ RGB –∏ –∏–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img = cv2.resize(img, (img_size, img_size))
                X.append(img)
                y_age.append(age / 100.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–æ–∑—Ä–∞—Å—Ç
                y_gender.append(gender)
                processed_count += 1
                
            except Exception as e:
                logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª {basename}: {str(e)}")
                error_count += 1
                continue
        
        if processed_count == 0:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–∫–∏ –≤ numpy –º–∞—Å—Å–∏–≤—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
        X = np.array(X, dtype="float32") / 255.0
        y_age = np.array(y_age, dtype="float32")
        y_gender = np.array(y_gender, dtype="float32")
        
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {processed_count}")
        if error_count > 0:
            logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫: {error_count}")
        
        return X, y_age, y_gender
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        raise

def predict_image(model_path: str, image_path: str) -> None:
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç –∏ –ø–æ–ª –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.
    
    Args:
        model_path: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    """
    try:
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img_size_ch = int(input("–í—ã–±–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ –≤ –ø—Ä–æ–≤–µ—Ä–∫–µ (1 - 32px, 2 - 64px, 3 - 128px): "))
        img_size = config.IMAGE_SIZES.get(img_size_ch)
        if not img_size:
            raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        model = models.load_model(model_path)
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (img_size, img_size))
        img = img / 255.0
        img = np.expand_dims(img, axis=0)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        gender_pred, age_pred = model.predict(img)
        gender = "–ú—É–∂—á–∏–Ω–∞" if gender_pred[0][0] < 0.5 else "–ñ–µ–Ω—â–∏–Ω–∞"
        age = max(0, int(age_pred[0][0] * 100))
        
        print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –ø–æ–ª: {gender}")
        print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç: {age}")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
        print("üò¢–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")

def setup_environment() -> None:
    """
    –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GPU/CPU, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.
    """
    global error
    
    if __name__ == "__main__":
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏
        for module, version in config.REQUIRED_MODULES.items():
            try:
                importlib.import_module(module)
            except ModuleNotFoundError:
                install_module(module, version)
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ AMD GPU
            is_amd = False
            try:
                import torch_hip
                is_amd = True
            except ImportError:
                pass

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º PyTorch –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ GPU
            if is_amd:
                torch_args = [
                    sys.executable, "-m", "pip", "install", "torch", "torchvision", "torchaudio",
                    "--index-url", "https://download.pytorch.org/whl/rocm5.4.2",
                    "--disable-pip-version-check", "--no-warn-script-location"
                ]
            else:
                torch_args = [
                    sys.executable, "-m", "pip", "install", "torch", "torchvision", "torchaudio",
                    "--index-url", "https://download.pytorch.org/whl/cu118",
                    "--disable-pip-version-check", "--no-warn-script-location"
                ]
            
            if IS_LINUX:
                torch_args.append("--break-system-packages")
                
            subprocess.run(torch_args, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            logger.info("PyTorch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except subprocess.CalledProcessError as e:
            error = True
            logger.error(f"–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ PyTorch: {str(e)}")

def calculate_optimal_parameters(vram: float, dram: float) -> Dict[str, Union[int, float]]:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏.
    
    Args:
        vram: –û–±—ä–µ–º VRAM –≤ –ì–ë
        dram: –û–±—ä–µ–º DRAM –≤ –ì–ë
    
    Returns:
        Dict —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if vram >= 8 and dram >= 16:
        max_img_size = 128
    elif vram >= 4 and dram >= 8:
        max_img_size = 64
    else:
        max_img_size = 32
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è GPU
    if vram >= 8:
        gpu_batch_size = min(128, int(vram * 8))
    elif vram >= 4:
        gpu_batch_size = min(64, int(vram * 6))
    else:
        gpu_batch_size = min(32, int(vram * 4))
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è CPU
    if dram >= 32:
        cpu_batch_size = min(128, int(dram * 2))
    elif dram >= 16:
        cpu_batch_size = min(64, int(dram * 1.5))
    else:
        cpu_batch_size = min(32, int(dram))
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
    if vram >= 4 and dram >= 8:
        recommended_mode = "GPU" if vram >= 6 else "HYBRID"
    else:
        recommended_mode = "CPU"
    
    return {
        "max_img_size": max_img_size,
        "gpu_batch_size": gpu_batch_size,
        "cpu_batch_size": cpu_batch_size,
        "recommended_mode": recommended_mode
    }

def configure_tensorflow(gpu_name: str, vram: float, dram: float) -> Tuple[tf.distribute.Strategy, int, int]:
    """
    –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç TensorFlow –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GPU/CPU —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π.
    
    Args:
        gpu_name: –ù–∞–∑–≤–∞–Ω–∏–µ GPU
        vram: –û–±—ä–µ–º VRAM –≤ –ì–ë
        dram: –û–±—ä–µ–º DRAM –≤ –ì–ë
    
    Returns:
        Tuple —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ TensorFlow
    """
    optimal_params = calculate_optimal_parameters(vram, dram)
    
    print(f"\n–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤–∞—à–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
    print(f"- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {optimal_params['max_img_size']}px")
    print(f"- –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: {optimal_params['recommended_mode']}")
    print(f"- –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è GPU: {optimal_params['gpu_batch_size']}")
    print(f"- –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è CPU: {optimal_params['cpu_batch_size']}\n")
    
    if gpu_name != "CPU":
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
        while True:
            use_mode = input(f"–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º (1 - GPU, 2 - CPU, 3 - GPU + CPU) [—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è {optimal_params['recommended_mode']}]: ").strip()
            if use_mode in ["1", "2", "3"]:
                break
            print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ 1, 2 –∏–ª–∏ 3.")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º TensorFlow –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
        if use_mode == "1" and vram > 0:
            os.environ["CUDA_VISIBLE_DEVICES"] = "0"
            strategy = tf.distribute.MirroredStrategy(devices=["/gpu:0"])
            if "CUDA" in gpu_name or (IS_LINUX and "AMD" in gpu_name):
                tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU: {gpu_name} —Å {vram:.2f} –ì–ë VRAM")
            batch_size = optimal_params['gpu_batch_size']
        elif use_mode == "2":
            strategy = tf.distribute.MirroredStrategy(devices=["/cpu:0"])
            os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU —Å {dram:.2f} –ì–ë DRAM")
            batch_size = optimal_params['cpu_batch_size']
        else:
            strategy = tf.distribute.MirroredStrategy(devices=["/gpu:0", "/cpu:0"])
            logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º GPU + CPU")
            batch_size = min(optimal_params['gpu_batch_size'], optimal_params['cpu_batch_size'])
    else:
        os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
        logger.info(f"GPU –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU —Å {dram:.2f} –ì–ë DRAM")
        strategy = tf.distribute.MirroredStrategy(devices=["/cpu:0"])
        batch_size = optimal_params['cpu_batch_size']
    
    return strategy, batch_size, optimal_params['max_img_size']

def train_model(X_train, y_gender_train, y_age_train, X_test, y_gender_test, y_age_test, batch_size: int, img_size: int) -> None:
    """
    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞ –∏ –ø–æ–ª–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö.
    
    Args:
        X_train: –û–±—É—á–∞—é—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        y_gender_train: –ú–µ—Ç–∫–∏ –ø–æ–ª–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        y_age_train: –ú–µ—Ç–∫–∏ –≤–æ–∑—Ä–∞—Å—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        X_test: –¢–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        y_gender_test: –ú–µ—Ç–∫–∏ –ø–æ–ª–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        y_age_test: –ú–µ—Ç–∫–∏ –≤–æ–∑—Ä–∞—Å—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        img_size: –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    """
    try:
        print("–°–æ–∑–¥–∞—é –º–æ–¥–µ–ª—å...")
        input = Input(shape=(img_size, img_size, 3))
        
        # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if img_size >= 128:
            x = layers.Conv2D(64, (3, 3), activation='relu')(input)
            x = layers.MaxPooling2D((2, 2))(x)
            x = layers.Conv2D(128, (3, 3), activation='relu')(x)
            x = layers.MaxPooling2D((2, 2))(x)
            x = layers.Conv2D(256, (3, 3), activation='relu')(x)
            x = layers.MaxPooling2D((2, 2))(x)
        elif img_size >= 64:
            x = layers.Conv2D(32, (3, 3), activation='relu')(input)
            x = layers.MaxPooling2D((2, 2))(x)
            x = layers.Conv2D(64, (3, 3), activation='relu')(x)
            x = layers.MaxPooling2D((2, 2))(x)
        else:
            x = layers.Conv2D(32, (3, 3), activation='relu')(input)
            x = layers.MaxPooling2D((2, 2))(x)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
        x = layers.Flatten()(x)
        x = layers.Dense(128, activation='relu')(x)
        gender_output = layers.Dense(1, activation='sigmoid', name='gender')(x)
        age_output = layers.Dense(1, activation='linear', name='age')(x)

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        model = Model(inputs=input, outputs=[gender_output, age_output])

        # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
        model.compile(
            optimizer='adam',
            loss={'gender': 'binary_crossentropy', 'age': 'mse'},
            metrics={'gender': 'accuracy', 'age': 'mae'}
        )

        print("–û–±—É—á–∞—é –º–æ–¥–µ–ª—å...")
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model.fit(
            X_train, [y_gender_train, y_age_train],
            batch_size=batch_size,
            epochs=50,
            validation_data=(X_test, [y_gender_test, y_age_test]),
            callbacks=[
                EarlyStopping(
                    monitor='val_loss',
                    patience=3,
                    restore_best_weights=True
                )
            ]
        )

        print("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        model.save("utkface_model.keras")
        print("üéâ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
        
    except tf.errors.ResourceExhaustedError:
        logger.error("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à–∏–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞.")
        raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –º–µ–Ω—å—à–∏–π —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
        raise

if __name__ == "__main__":
    # –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã
    setup_environment()
    
    if error == False:
        logger.info("–í—Å–µ –º–æ–¥—É–ª–∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
    else:
        logger.error("–û—à–∏–±–∫–∞ –º–æ–¥—É–ª–µ–π!")
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ—á–∏—Å—Ç–∫—É —ç–∫—Ä–∞–Ω–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –û–°
    if IS_WINDOWS:
        clear = lambda: os.system('cls')
    if IS_LINUX:
        clear = lambda: os.system('clear')
    
    clear()
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    tf.get_logger().setLevel('WARNING')
    os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
    cv2.setLogLevel(0)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ
    print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ OC: {platform.system()}")
    vram, dram, gpu_name = get_available_memory()
    strategy, batch_size, max_img_size = configure_tensorflow(gpu_name, vram, dram)
    
    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–µ–π—Å—Ç–≤–∏–µ
    while True:
        choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ (1 - –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏, 2 - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏): ").strip()
        if choice in ["1", "2"]:
            break
        print("–û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥. –í—ã–±–µ—Ä–∏—Ç–µ 1 –∏–ª–∏ 2.")
    
    clear()
    
    if choice == "1":
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        available_sizes = {k: v for k, v in config.IMAGE_SIZES.items() if v <= max_img_size}
        print(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –≤–∞—à–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
        for size_id, size in available_sizes.items():
            print(f"{size_id} - {size}px")
        
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        while True:
            try:
                img_size_ch = int(input(f"–í—ã–±–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ (1-{len(available_sizes)}): "))
                img_size = available_sizes.get(img_size_ch)
                if img_size:
                    break
                print(f"–û—à–∏–±–∫–∞: –≤—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤: {', '.join(map(str, available_sizes.keys()))}")
            except ValueError:
                print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ")

        print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        X, y_age, y_gender = load_utkface_data("./UTKFace", img_size)
        if len(X) == 0:
            raise ValueError("–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É.")

        print("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è y_gender:", np.unique(y_gender))

        # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        X_train, X_test, y_age_train, y_age_test, y_gender_train, y_gender_test = train_test_split(
            X, y_age, y_gender, test_size=0.2, random_state=42
        )
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        train_model(X_train, y_gender_train, y_age_train, X_test, y_gender_test, y_age_test, batch_size, img_size)

    elif choice == "2":
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        image_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é: ").strip()
        model_path = "utkface_model.keras"
        predict_image(model_path, image_path)